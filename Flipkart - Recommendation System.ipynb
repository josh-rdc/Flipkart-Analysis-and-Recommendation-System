{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data importation and manipulation\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization, exploratory and result analysis\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress 'deprecated' warnings, added in final run to clean notebook when printing into pdf\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_csv_dataset(file_path):\n",
    "    df = pd.read_csv(file_path, header=0, encoding='latin-1')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipkart_data = r\"Dataset\\flipkart_com-products.csv\"\n",
    "flipkart_data_3 =r\"flipkart_data_df3.csv\"\n",
    "\n",
    "flipkart_data_df = import_csv_dataset(flipkart_data)\n",
    "flipkart_data_df3 = import_csv_dataset(flipkart_data_3)\n",
    "\n",
    "flipkart_id_name = flipkart_data_df[['pid', 'product_name']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendation System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Josh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Initialize lemmatizer and stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stop_words = set(stopwords.words('english')) - {\"not\", \"no\"}  # Keep negations\n",
    "    \n",
    "    # Convert to string and lowercase\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Remove special characters and digits but keep words\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # Lemmatization \n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "flipkart_data_df3['description'] = flipkart_data_df3['description'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 300)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(stop_words=\"english\", max_features=500)\n",
    "tfidf_matrix = tfidf.fit_transform(flipkart_data_df3['description'])\n",
    "\n",
    "print(tfidf_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "cosine_sim = cosine_similarity(tfidf_matrix,\n",
    "                               tfidf_matrix)\n",
    "\n",
    "print(cosine_sim.shape)\n",
    "cosine_sim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 20000)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Convert to a sparse matrix to reduce size\n",
    "cosine_sim_sparse = csr_matrix(cosine_sim)\n",
    "\n",
    "print(cosine_sim_sparse.shape)  # Same shape but much smaller memory footprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the sparse matrix\n",
    "with open('cosine_sim_sparse.pkl', 'wb') as f:\n",
    "    pickle.dump(cosine_sim_sparse, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix split and saved successfully in 'RecommendationFile/' folder.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Ensure the directory exists\n",
    "folder_path = r\"RecommendationFile\"\n",
    "os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "# Load cosine_sim\n",
    "with open(os.path.join(folder_path, \"cosine_sim.pkl\"), \"rb\") as f:\n",
    "    cosine_sim = pickle.load(f)\n",
    "\n",
    "# Split into 50 parts\n",
    "num_parts = 50\n",
    "split_arrays = np.array_split(cosine_sim, num_parts)\n",
    "\n",
    "# Save each part separately inside the folder\n",
    "for i, part in enumerate(split_arrays):\n",
    "    file_path = os.path.join(folder_path, f'cosine_sim_part_{i}.pkl')\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(part, f)\n",
    "\n",
    "print(\"Cosine similarity matrix split and saved successfully in 'RecommendationFile/' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_5_similar(index, df, df_name, cosine_sim):\n",
    "    # Get the PID of the given index\n",
    "    pid = df.loc[index, 'pid']\n",
    "    \n",
    "    # Get the product name from flipkart_id_name using pid\n",
    "    product_name = df_name.loc[df_name['pid'] == pid, 'product_name'].values[0]\n",
    "    \n",
    "    # Get similarity scores for the given index and sort them in descending order\n",
    "    sim_scores = list(enumerate(cosine_sim[index]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]  # Exclude itself\n",
    "    \n",
    "    # Get the top 5 similar product indices\n",
    "    top_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Get corresponding product IDs and names\n",
    "    top_pids = df.loc[top_indices, 'pid'].values\n",
    "    top_names = df_name.loc[df_name['pid'].isin(top_pids), 'product_name'].values\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Product ID: {pid}\")\n",
    "    print(f\"Product Name: {product_name}\")\n",
    "    for i, (top_pid, top_name) in enumerate(zip(top_pids, top_names), start=1):\n",
    "        print(f\"Top {i}: {top_pid} - {top_name}\")\n",
    "\n",
    "    return pid, product_name, top_pids, top_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity matrix successfully reconstructed.\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"RecommendationFile\"\n",
    "\n",
    "# Load all parts\n",
    "num_parts = 50\n",
    "cosine_sim_parts = []\n",
    "\n",
    "for i in range(num_parts):\n",
    "    file_path = os.path.join(folder_path, f'cosine_sim_part_{i}.pkl')\n",
    "    with open(file_path, 'rb') as f:\n",
    "        cosine_sim_parts.append(pickle.load(f))\n",
    "\n",
    "# Merge into a single array\n",
    "cosine_sim = np.vstack(cosine_sim_parts)\n",
    "\n",
    "print(\"Cosine similarity matrix successfully reconstructed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the cosine similarity matrix\n",
    "# cosine_sim_path = r\"cosine_sim.pkl\"\n",
    "\n",
    "# with open(cosine_sim_path, 'rb') as f:\n",
    "#     cosine_sim = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>product_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRTEH2FF9KEDEFGF</td>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBEEH3QGU7MFYJFY</td>\n",
       "      <td>FabHomeDecor Fabric Double Sofa Bed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHOEH4GRSUBJGZXE</td>\n",
       "      <td>AW Bellies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRTEH2F6HUZMQ6SJ</td>\n",
       "      <td>Alisha Solid Women's Cycling Shorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PSOEH3ZYDMSYARJ5</td>\n",
       "      <td>Sicons All Purpose Arnica Dog Shampoo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>STIE7KFJAKSTDY9G</td>\n",
       "      <td>WallDesign Small Vinyl Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>STIE9F5URNQGJCGH</td>\n",
       "      <td>Wallmantra Large Vinyl Stickers Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>STIE7VAYDKQZEBSD</td>\n",
       "      <td>Elite Collection Medium Acrylic Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>STIE8YSVEPPCZ42Y</td>\n",
       "      <td>Elite Collection Medium Acrylic Sticker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>STIE88KN9ZDSGZKY</td>\n",
       "      <td>Elite Collection Medium Acrylic Sticker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pid                             product_name\n",
       "0      SRTEH2FF9KEDEFGF      Alisha Solid Women's Cycling Shorts\n",
       "1      SBEEH3QGU7MFYJFY      FabHomeDecor Fabric Double Sofa Bed\n",
       "2      SHOEH4GRSUBJGZXE                               AW Bellies\n",
       "3      SRTEH2F6HUZMQ6SJ      Alisha Solid Women's Cycling Shorts\n",
       "4      PSOEH3ZYDMSYARJ5    Sicons All Purpose Arnica Dog Shampoo\n",
       "...                 ...                                      ...\n",
       "19995  STIE7KFJAKSTDY9G           WallDesign Small Vinyl Sticker\n",
       "19996  STIE9F5URNQGJCGH  Wallmantra Large Vinyl Stickers Sticker\n",
       "19997  STIE7VAYDKQZEBSD  Elite Collection Medium Acrylic Sticker\n",
       "19998  STIE8YSVEPPCZ42Y  Elite Collection Medium Acrylic Sticker\n",
       "19999  STIE88KN9ZDSGZKY  Elite Collection Medium Acrylic Sticker\n",
       "\n",
       "[20000 rows x 2 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart_id_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Product ID: SBEEH3QGU7MFYJFY\n",
      "Product Name: FabHomeDecor Fabric Double Sofa Bed\n",
      "Top 1: SBEEH3QGYGHFUEXN - FabHomeDecor Fabric Double Sofa Bed\n",
      "Top 2: SBEEH3QGAYAEPRCG - FabHomeDecor Fabric Double Sofa Bed\n",
      "Top 3: SBEEH3QGWRGG3J6Q - FabHomeDecor Fabric Double Sofa Bed\n",
      "Top 4: SOFEGDV3HGY3AB43 - Ethnic Handicrafts Solid Wood Single Bed\n",
      "Top 5: BDDEH29EWHWRAPWG - Comfort Couch Engineered Wood 3 Seater Sofa\n"
     ]
    }
   ],
   "source": [
    "pid, product_name, top_pids, top_names = get_top_5_similar(1, flipkart_data_df3, flipkart_id_name, cosine_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "100environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "275.2px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
